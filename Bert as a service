#MUST be running on Python >= 3.5 with Tensorflow >= 1.1
#dwnld and uncompress into say /tmp/english_L-12_H-768_A-12/ 
#(from https://github.com/hanxiao/bert-as-service/blob/master/README.md#getting-started)
conda activate p36
pip install scikit-learn
pip install tensorflow==1.14.0 #one point fourteen
pip install bert-serving-client bert-serving-server -U
#pip install ftfy
pip install --upgrade nltk
pip install --upgrade matplotlib
pip install --upgrade seaborn
pip install --upgrade numpy as np
pip install --upgrade pandas as pd
bert-serving-start -model_dir /home/antony/t2/uncased_L-12_H-768_A-12/ -num_worker=1 -max_seq_len=15
 
#-fixed_embed_length by bert-serving-start --help especially if you intend to use it as ELMo-like embedding.
#(or run the below code, from the bert repo : python example8.py -model_dir=uncased_L-12_H-768_A-12)

pip install bert-serving-client bert-serving-server -U

conda activate p36
#on python  ...
import pandas as pd
import sklearn
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import seaborn as sns
import logging
logging.getLogger("tensorflow").setLevel(logging.ERROR)
import sys
import tensorflow
import numpy as np
importÂ nltk
nltk.download('punkt')
from bert_serving.server import BertServer # still need this?
from bert_serving.client import BertClient
bc = BertClient()
from nltk import tokenize
time_start = time.time()
import csv

#Reading  paragraphs of text from csv file then and then encoding . 
#File contains a column, with 4 rows of paragraphs from 4 news article.
#Sentences per paragraph vary between 3 to 5. So vector dimensions vary from (768, 3) to (768, 5) 
def load_from_csv(file):
    df = pd.read_csv(file, error_bad_lines=False, nrows=1000)
    df = df.rename(str.lower, axis='columns')
    df['title'] = df['title'].apply(lambda x: x.replace("'s", " " "s").replace("\n"," "))
    df['title'] = df['title'].apply(lambda x: tokenize.sent_tokenize(x))
    df['encoded'] = df['title'].apply(lambda x: bc.encode(x))
    return df

df=load_from_csv('titlejson.csv')
             
# embeddings
embeddings = [i[0] for i in df['encoded']][1:]

with open('tensor.tsv', 'wt') as out_file:
    tsv_writer = csv.writer(out_file, delimiter='\t')
    for e in embeddings:
      tsv_writer.writerow(e)

# labels
df['short_str'] = df['title'].str.slice(0,10)
metadata=df['short_str'].iloc[1:]

with open('metadata.tsv', 'wt') as out_file:
    tsv_writer = csv.writer(out_file, delimiter='\t')
    for meta in metadata:
      tsv_writer.writerow([meta])

      
output32 and output33 uploaded to tensorflow embedded visualizer

#or:
bc.encode(['First do it', 'then do it right', 'then do it better'])

metadata = ['First do it', 'then do it right', 'then do it better']
df=bc.encode(metadata)

with open('output2.tsv', 'wt') as out_file:
    tsv_writer = csv.writer(out_file, delimiter='\t')
    for d in df:
      tsv_writer.writerow(X)
 
 with open('output3.tsv', 'wt') as out_file:
    tsv_writer = csv.writer(out_file, delimiter='\t')
    for meta in metadata:
      tsv_writer.writerow([meta])
ref:
https://towardsdatascience.com/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b
