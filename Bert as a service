#MUST be running on Python >= 3.5 with Tensorflow >= 1.1
#dwnld and uncompress into say /tmp/english_L-12_H-768_A-12/ 
#(from https://github.com/hanxiao/bert-as-service/blob/master/README.md#getting-started)

pip install tensorflow==1.10.0 #one point ten
pip install bert-serving-client bert-serving-server -U
pip install ftfy
pip install nltk
pip install --upgrade matplotlib
pip install seaborn
bert-serving-start -model_dir /home/antony/t2/uncased_L-12_H-768_A-12/ -num_worker=1 -max_seq_len=NONE
 
#-fixed_embed_length by bert-serving-start --help especially if you intend to use it as ELMo-like embedding.
#(or run the below code, from the bert repo : python example8.py -model_dir=uncased_L-12_H-768_A-12)

pip install bert-serving-client bert-serving-server -U

#on python  ...
import pandas as pd
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import seaborn as sns
import logging
logging.getLogger("tensorflow").setLevel(logging.ERROR)
import sys
import tensorflow
import numpy as np
import nltk
nltk.download('punkt')
from nltk import tokenize
from bert_serving.server import BertServer # still need this?
from bert_serving.client import BertClient
bc = BertClient()
from nltk import tokenize
from ftfy import fix_text
bc.encode(['First do it', 'then do it right', 'then do it better'])

def load_from_csv(file):
    df = pd.read_csv(file)
    df = df.rename(str.lower, axis='columns')
    df['paragraphs'] = df['paragraphs'].apply(lambda x: x.replace("'s", " " "s").replace("\n"," "))
    df['paragraphs'] = df['paragraphs'].apply(lambda x: tokenize.sent_tokenize(x))
    BertClient=bc
    df['encoded'] = df['paragraphs'].apply(lambda x: BertClient.encode(x))
    return df

df=load_from_csv('x.csv')
             
Xa...Xf = encode_n_pool(text) # ths would be X
X1 = np.mean(df.iat[0,1], axis=0) 
X2 = np.mean(df.iat[1,1], axis=0) 
X3 = np.mean(df.iat[2,1], axis=0) 
X4 = np.mean(df.iat[3,1], axis=0) 

X=np.column_stack([Xa,Xb,Xd,Xd])
XT=X.T
feat_cols = [ 'pixel'+str(i) for i in range(XT.shape[1]) ]
df = pd.DataFrame(XT,columns=feat_cols)

numbers = [1, 2, 3, 4]
df['y'] = numbers
df['label'] = df['y'].apply(lambda i: str(i))


np.random.seed(42)  
rndperm = np.random.permutation(df.shape[0])
pca = PCA(n_components=3)
pca_result = pca.fit_transform(df[feat_cols].values)

df['pca-one'] = pca_result[:,0]
df['pca-two'] = pca_result[:,1] 
df['pca-three'] = pca_result[:,2]

print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))

plt.figure(figsize=(16,10))
sns.scatterplot(
    x="pca-one", y="pca-two",
    hue="y",
    palette=sns.color_palette("hls", 4),
    data=df.loc[rndperm,:],
    legend="full",
    alpha=0.3
)
plt.show()

ax = plt.figure(figsize=(16,10)).gca(projection='3d')
ax.scatter(
    xs=df.loc[rndperm,:]["pca-one"], 
    ys=df.loc[rndperm,:]["pca-two"], 
    zs=df.loc[rndperm,:]["pca-three"], 
    c=df.loc[rndperm,:]["y"], 
    cmap='tab10'
)
ax.set_xlabel('pca-one')
ax.set_ylabel('pca-two')
ax.set_zlabel('pca-three')
plt.show()

ref:
https://towardsdatascience.com/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b
