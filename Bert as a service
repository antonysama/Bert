# Goal is to run Bert server & client. 
#MUST be running on Python >= 3.5 with Tensorflow >= 1.1
pip install tensorflow==1.10.0 #one point ten, not 2.0
pip install bert-serving-client bert-serving-server -U
#dwnld and uncompress into say /tmp/english_L-12_H-768_A-12/ 
#(from https://github.com/hanxiao/bert-as-service/blob/master/README.md#getting-started)
bert-serving-start -model_dir /home/antony/t2/uncased_L-12_H-768_A-12/ -num_worker=1 -pooling_strategy FIRST_TOKEN -show_tokens_to_client
-max_seq_len NONE pooling_layer -4 -3 -2 -1 -gpu  
#  you can send any sequence shorter than max_position_embeddings (usually 512) defined in bert.json.
# Length restriction on server side is waived. You may also want to check the new argument 
#-fixed_embed_length by bert-serving-start --help especially if you intend to use it as ELMo-like embedding.
#(or run the below code, from the bert repo : python example8.py -model_dir=uncased_L-12_H-768_A-12)
#to get the concatenated layers back.
pooling_layers = np.split(embeddings_4321, 4, axis=0)
#further to calculate mean used this:
mean4321 = np.mean(pooling_layers, axis=0)
#Error: The name tf.logging.ERROR is deprecated. Please use tf.compat.v1.logging.ERROR instead (see below):
#https://stackoverflow.com/questions/55081911/tensorflow-2-0-0-alpha0-tf-logging-set-verbosity:

#on python run ...
import logging
logging.getLogger("tensorflow").setLevel(logging.ERROR)
import sys
import tensorflow
import numpy as np
from bert_serving.server import BertServer # still need this?
from bert_serving.client import BertClient
bc = BertClient()
bc.encode(['First do it', 'then do it right', 'then do it better'])

#"Just encode! Don't even bother to batch, the server will take care of it."
# prepare your sent in advance
bc = BertClient()
my_sentences = [s for s in my_corpus.iter()]
# doing encoding in one-shot
vec = bc.encode(my_sentences)
#It will return a ndarray (or List[List[float]] if you wish),
#in which each row is a fixed-length vector representing a sentence.

from termcolor import colored
from bert_serving.server.helper import get_run_args

if __name__ == '__main__':
    args = get_run_args()
    server = BertServer(args)
    server.start()
    server.join()

from termcolor import colored
prefix_q = '##### **Q:** '
topk = 5

with open('README.md') as fp:
    questions = [v.replace(prefix_q, '').strip() for v in fp if v.strip() and v.startswith(prefix_q)]
    print('%d questions loaded, avg. len of %d' % (len(questions), np.mean([len(d.split()) for d in questions])))
    
with BertClient(ip='192.168.0.10') as bc:
    doc_vecs = bc.encode(questions)

    while True:
        query = input(colored('your question: ', 'green'))
        query_vec = bc.encode([query])[0]
        # compute normalized dot product as score
        score = np.sum(query_vec * doc_vecs, axis=1) / np.linalg.norm(doc_vecs, axis=1)
        topk_idx = np.argsort(score)[::-1][:topk]
        print('top %d questions similar to "%s"' % (topk, colored(query, 'green')))
        for idx in topk_idx:
            print('> %s\t%s' % (colored('%.1f' % score[idx], 'cyan'), colored(questions[idx], 'yellow')))


# References:
# Staring server & client: https://buildmedia.readthedocs.org/media/pdf/bert-as-service/latest/bert-as-service.pdf
# Tutorials: https://github.com/antonysama/bert-as-service
# ...more tutorials: https://bert-as-service.readthedocs.io/en/latest/tutorial/token-embed.html
# Repo: https://github.com/google-research/bert
# Examples: https://github.com/hanxiao/bert-as-service/blob/master/README.md
