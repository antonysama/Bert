#MUST be running on Python >= 3.5 with Tensorflow >= 1.1
pip install tensorflow==1.10.0 #one point ten
pip install bert-serving-client bert-serving-server -U
pip install ftfy
pip install nltk
pip install --upgrade matplotlib
pip install seaborn
#dwnld and uncompress into say /tmp/english_L-12_H-768_A-12/ 
#(from https://github.com/hanxiao/bert-as-service/blob/master/README.md#getting-started)
bert-serving-start -model_dir /home/antony/t2/uncased_L-12_H-768_A-12/ -num_worker=1 
#  you can send any sequence shorter than max_position_embeddings (usually 512) defined in bert.json.
# Length restriction on server side is waived. You may also want to check the new argument 
#-fixed_embed_length by bert-serving-start --help especially if you intend to use it as ELMo-like embedding.
#(or run the below code, from the bert repo : python example8.py -model_dir=uncased_L-12_H-768_A-12)

pip install bert-serving-client bert-serving-server -U

#on python  ...
import pandas as pd
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
import logging
logging.getLogger("tensorflow").setLevel(logging.ERROR)
import sys
import tensorflow
import numpy as np
from bert_serving.server import BertServer # still need this?
from bert_serving.client import BertClient
bc = BertClient()
from nltk import tokenize
from ftfy import fix_text
bc.encode(['First do it', 'then do it right', 'then do it better'])

text = 'Bert encodes a sentence by producing a vector array for each sentence. The cumulative dimensions would be large. However, sentence vectors across paragraphs  can be pooled in ways that reduce the dimensions of vectors. The number of hidden units is predefined. Each sentence is translated to a 768-dimensional vector. If you are using BERT model released by Google, then the number of hidden units is either 768 or 1024'

def encode_n_pool(text, bertClient=bc):
 sentences = tokenize.sent_tokenize(fix_text(text))
 encoded = bertClient.encode(sentences)
 return encoded  

def read_from_txt(filename):
    if filename.endswith(".txt"):
        with open(filename, 'r') as f:
            return f.read() # only if reading txt file use V
             
text = read_from_txt('test.txt') # only if read_from_text is used ^

encoding = encode_n_pool(text) # this would be X

feat_cols = [ 'pixel'+str(i) for i in range(X.shape[1]) ]

#random seed & plot of pca1 & 2:
np.random.seed(42)  
rndperm = np.random.permutation(df.shape[0])

plt.figure(figsize=(16,10))
sns.scatterplot(
    x="pca-one", y="pca-two",
    palette=sns.color_palette("hls", 10),
    data=df.loc[rndperm,:],
    legend="full",
    alpha=0.3
	)
plot.show()
